/*
 * PostgreSQL Parser Lexer - Token Definitions
 *
 * This file implements the core token system for the PostgreSQL lexer,
 * porting the token definitions from PostgreSQL's gram.y and scanner.h.
 * Ported from postgres/src/include/parser/scanner.h and postgres/src/backend/parser/gram.y
 *
 * IMPORTANT: These token constants are TEMPORARY scaffolding for Phase 2A development.
 * In Phase 3 (Grammar & Parsing), these will be REPLACED by goyacc-generated constants
 * from go/parser/grammar/postgres.y. The generated postgres.go file will contain the
 * authoritative token definitions that the lexer will import and use.
 *
 * This approach follows the Vitess pattern where the lexer uses token constants
 * generated by goyacc from the grammar file, not manually defined constants.
 *
 * Phase 2A: Manual constants (this file) - for lexer development and testing
 * Phase 3+: Generated constants from postgres.y - for parser integration
 */

package parser

import (
	"fmt"
	"strings"
)

// TokenType represents the type of a lexical token
// Ported from postgres/src/backend/parser/gram.y token definitions
type TokenType int

// Core token types from PostgreSQL grammar
// These values must match PostgreSQL's token numbering for compatibility
// Ported from postgres/src/backend/parser/gram.y:715-725 (%token definitions)
const (
	// Special tokens - internal to lexer
	INVALID TokenType = 0
	EOF     TokenType = 1

	// Basic ASCII tokens (32-126) are represented by their character value
	// Single character tokens like '(', ')', '+', '-', etc.

	// Multi-character tokens start at 258 (following PostgreSQL convention)
	// Ported from postgres/src/include/parser/scanner.h:57 comment "IDENT = 258 and so on"
	// Token definitions from postgres/src/backend/parser/gram.y:692-695
	IDENT   TokenType = 258 // Identifier - postgres/src/backend/parser/gram.y:692
	UIDENT  TokenType = 259 // Unreserved identifier - postgres/src/backend/parser/gram.y:692
	FCONST  TokenType = 260 // Floating point constant - postgres/src/backend/parser/gram.y:692
	SCONST  TokenType = 261 // String constant - postgres/src/backend/parser/gram.y:692
	USCONST TokenType = 262 // Unterminated string constant (error case) - postgres/src/backend/parser/gram.y:692
	BCONST  TokenType = 263 // Bit string constant - postgres/src/backend/parser/gram.y:692
	XCONST  TokenType = 264 // Hexadecimal constant - postgres/src/backend/parser/gram.y:692
	Op      TokenType = 265 // Operator - postgres/src/backend/parser/gram.y:692
	ICONST  TokenType = 266 // Integer constant - postgres/src/backend/parser/gram.y:693
	PARAM   TokenType = 267 // Parameter ($1, $2, etc.) - postgres/src/backend/parser/gram.y:693

	// Multi-character operators - postgres/src/backend/parser/gram.y:694-695
	TYPECAST       TokenType = 268 // '::' - postgres/src/backend/parser/gram.y:694
	DOT_DOT        TokenType = 269 // '..' - postgres/src/backend/parser/gram.y:694
	COLON_EQUALS   TokenType = 270 // ':=' - postgres/src/backend/parser/gram.y:694
	EQUALS_GREATER TokenType = 271 // '=>' - postgres/src/backend/parser/gram.y:694
	LESS_EQUALS    TokenType = 272 // '<=' - postgres/src/backend/parser/gram.y:695
	GREATER_EQUALS TokenType = 273 // '>=' - postgres/src/backend/parser/gram.y:695
	NOT_EQUALS     TokenType = 274 // '<>' or '!=' - postgres/src/backend/parser/gram.y:695

	// Reserved keywords - temporary for Phase 2E testing
	// In Phase 3, these will be replaced by goyacc-generated constants
	SELECT TokenType = 275 // SELECT keyword
	FROM   TokenType = 276 // FROM keyword
	WHERE  TokenType = 277 // WHERE keyword

	// Special mode tokens for PL/pgSQL compatibility
	FORMAT_LA            TokenType = 278 // FORMAT lookahead
	NOT_LA               TokenType = 279 // NOT lookahead
	NULLS_LA             TokenType = 280 // NULLS lookahead
	WITH_LA              TokenType = 281 // WITH lookahead
	WITHOUT_LA           TokenType = 282 // WITHOUT lookahead
	MODE_TYPE_NAME       TokenType = 283 // Type name mode
	MODE_PLPGSQL_EXPR    TokenType = 284 // PL/pgSQL expression mode
	MODE_PLPGSQL_ASSIGN1 TokenType = 285 // PL/pgSQL assignment mode 1
	MODE_PLPGSQL_ASSIGN2 TokenType = 286 // PL/pgSQL assignment mode 2
	MODE_PLPGSQL_ASSIGN3 TokenType = 287 // PL/pgSQL assignment mode 3
)

// TokenValue represents the union of possible token values
// This is the Go equivalent of PostgreSQL's core_YYSTYPE union
// Ported from postgres/src/include/parser/scanner.h:29-34
type TokenValue struct {
	// Only one of these fields should be set for any given token
	Ival    int    // For integer literals (ICONST, PARAM) - postgres/src/include/parser/scanner.h:31
	Str     string // For identifiers and non-integer literals - postgres/src/include/parser/scanner.h:32
	Keyword string // For canonical spelling of keywords - postgres/src/include/parser/scanner.h:33
}

// Token represents a single lexical token with its type, value, and position
type Token struct {
	Type     TokenType  // The type of token
	Value    TokenValue // The token's value
	Position int        // Byte offset from start of input (YYLTYPE equivalent)
	Text     string     // Raw text that produced this token
}

// NewToken creates a new token with the given parameters
func NewToken(tokenType TokenType, position int, text string) *Token {
	return &Token{
		Type:     tokenType,
		Value:    TokenValue{Str: text},
		Position: position,
		Text:     text,
	}
}

// NewIntToken creates a new integer token
func NewIntToken(value int, position int, text string) *Token {
	return &Token{
		Type:     ICONST,
		Value:    TokenValue{Ival: value},
		Position: position,
		Text:     text,
	}
}

// NewStringToken creates a new string token
func NewStringToken(tokenType TokenType, value string, position int, text string) *Token {
	return &Token{
		Type:     tokenType,
		Value:    TokenValue{Str: value},
		Position: position,
		Text:     text,
	}
}

// NewKeywordToken creates a new keyword token
func NewKeywordToken(tokenType TokenType, keyword string, position int, text string) *Token {
	return &Token{
		Type:     tokenType, // Use the keyword's specific token type
		Value:    TokenValue{Keyword: keyword, Str: strings.ToLower(keyword)},
		Position: position,
		Text:     text,
	}
}

// NewParamToken creates a new parameter token ($1, $2, etc.)
func NewParamToken(paramNum int, position int, text string) *Token {
	return &Token{
		Type:     PARAM,
		Value:    TokenValue{Ival: paramNum},
		Position: position,
		Text:     text,
	}
}

// IsStringLiteral returns true if the token is a string literal type
func (t *Token) IsStringLiteral() bool {
	return t.Type == SCONST || t.Type == USCONST
}

// IsNumericLiteral returns true if the token is a numeric literal type
func (t *Token) IsNumericLiteral() bool {
	return t.Type == ICONST || t.Type == FCONST
}

// IsBitStringLiteral returns true if the token is a bit string literal type
func (t *Token) IsBitStringLiteral() bool {
	return t.Type == BCONST || t.Type == XCONST
}

// IsOperator returns true if the token is an operator
func (t *Token) IsOperator() bool {
	return t.Type == Op ||
		t.Type == TYPECAST ||
		t.Type == DOT_DOT ||
		t.Type == COLON_EQUALS ||
		t.Type == EQUALS_GREATER ||
		t.Type == LESS_EQUALS ||
		t.Type == GREATER_EQUALS ||
		t.Type == NOT_EQUALS
}

// IsIdentifier returns true if the token is an identifier
func (t *Token) IsIdentifier() bool {
	return t.Type == IDENT || t.Type == UIDENT
}

// String returns a string representation of the token for debugging
func (t *Token) String() string {
	typeName := tokenTypeNames[t.Type]
	if typeName == "" {
		if t.Type <= 126 && t.Type >= 32 {
			// ASCII character token
			typeName = string(rune(t.Type))
		} else {
			typeName = "UNKNOWN"
		}
	}

	return fmt.Sprintf("Token{Type: %s, Value: %v, Position: %d, Text: %q}",
		typeName, t.Value, t.Position, t.Text)
}

// tokenTypeNames provides string names for token types (for debugging)
var tokenTypeNames = map[TokenType]string{
	INVALID:              "INVALID",
	EOF:                  "EOF",
	IDENT:                "IDENT",
	UIDENT:               "UIDENT",
	FCONST:               "FCONST",
	SCONST:               "SCONST",
	USCONST:              "USCONST",
	BCONST:               "BCONST",
	XCONST:               "XCONST",
	Op:                   "Op",
	ICONST:               "ICONST",
	PARAM:                "PARAM",
	TYPECAST:             "TYPECAST",
	DOT_DOT:              "DOT_DOT",
	COLON_EQUALS:         "COLON_EQUALS",
	EQUALS_GREATER:       "EQUALS_GREATER",
	LESS_EQUALS:          "LESS_EQUALS",
	GREATER_EQUALS:       "GREATER_EQUALS",
	NOT_EQUALS:           "NOT_EQUALS",
	FORMAT_LA:            "FORMAT_LA",
	NOT_LA:               "NOT_LA",
	NULLS_LA:             "NULLS_LA",
	WITH_LA:              "WITH_LA",
	WITHOUT_LA:           "WITHOUT_LA",
	MODE_TYPE_NAME:       "MODE_TYPE_NAME",
	MODE_PLPGSQL_EXPR:    "MODE_PLPGSQL_EXPR",
	MODE_PLPGSQL_ASSIGN1: "MODE_PLPGSQL_ASSIGN1",
	MODE_PLPGSQL_ASSIGN2: "MODE_PLPGSQL_ASSIGN2",
	MODE_PLPGSQL_ASSIGN3: "MODE_PLPGSQL_ASSIGN3",
}
